{
  "paragraphs": [
    {
      "title": "Snippet 1 - zadanie",
      "text": "%spark\n\n/*\n     Waszym zadaniem jest odpowiednie zainicjalizowanie RDD wierzcholkow i krawedzi \n*/\n\nimport org.apache.spark.graphx._\nimport org.apache.spark.rdd.RDD\n\nval vertexArray \u003d Array(\n  (1L, (\"Alice\", 28)),\n  (2L, (\"Bob\", 27)),\n  (3L, (\"Charlie\", 65)),\n  (4L, (\"David\", 42)),\n  (5L, (\"Ed\", 55)),\n  (6L, (\"Fran\", 50))\n  )\nval edgeArray \u003d Array(\n  Edge(2L, 1L, 7),\n  Edge(2L, 4L, 2),\n  Edge(3L, 2L, 4),\n  Edge(3L, 6L, 3),\n  Edge(4L, 1L, 1),\n  Edge(5L, 2L, 2),\n  Edge(5L, 3L, 8),\n  Edge(5L, 6L, 3)\n  )\n  \n//val vertexRDD: RDD[(Long, (String, Int))] \u003d // Implement\n//val edgeRDD: RDD[Edge[Int]] \u003d // Implement\n",
      "dateUpdated": "Dec 5, 2016 7:40:05 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {},
          "map": {
            "baseMapType": "Streets",
            "isOnline": true,
            "pinCols": []
          }
        },
        "enabled": true,
        "title": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1480872016331_-47337552",
      "id": "20161204-172016_1368208492",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark.graphx._\n\nimport org.apache.spark.rdd.RDD\n\nvertexArray: Array[(Long, (String, Int))] \u003d Array((1,(Alice,28)), (2,(Bob,27)), (3,(Charlie,65)), (4,(David,42)), (5,(Ed,55)), (6,(Fran,50)))\n\nedgeArray: Array[org.apache.spark.graphx.Edge[Int]] \u003d Array(Edge(2,1,7), Edge(2,4,2), Edge(3,2,4), Edge(3,6,3), Edge(4,1,1), Edge(5,2,2), Edge(5,3,8), Edge(5,6,3))\n\nvertexRDD: org.apache.spark.rdd.RDD[(Long, (String, Int))] \u003d ParallelCollectionRDD[0] at parallelize at \u003cconsole\u003e:37\n\nedgeRDD: org.apache.spark.rdd.RDD[org.apache.spark.graphx.Edge[Int]] \u003d ParallelCollectionRDD[1] at parallelize at \u003cconsole\u003e:37\n"
      },
      "dateCreated": "Dec 4, 2016 5:20:16 PM",
      "dateStarted": "Dec 5, 2016 7:39:49 AM",
      "dateFinished": "Dec 5, 2016 7:39:51 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Snippet 2 - zadanie",
      "text": "%spark\n\n/*\n     Waszym zadaniem jest wyswietlenie uzytkownikow ktorzy maja przynajmniej 30 lat\n*/\n\nimport org.apache.spark.graphx._\nimport org.apache.spark.rdd.RDD\n\nval graph: Graph[(String, Int), Int] \u003d Graph(vertexRDD, edgeRDD)\n\n\n//graph.vertices.filter {\n//  case (id, (name, age)) \u003d\u003e /* implement */\n//}.collect.foreach {\n//  case (id, (name, age)) \u003d\u003e /* implement */\n//}\n\n\n/*\nOczekiwany rezultat:\n\n    David is 42\n    Fran is 50\n    Ed is 55\n    Charlie is 65\n*/\n\n",
      "dateUpdated": "Dec 5, 2016 7:42:44 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {},
          "map": {
            "baseMapType": "Streets",
            "isOnline": true,
            "pinCols": []
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1480872472551_-948958587",
      "id": "20161204-172752_794446119",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark.graphx._\n\nimport org.apache.spark.rdd.RDD\n\ngraph: org.apache.spark.graphx.Graph[(String, Int),Int] \u003d org.apache.spark.graphx.impl.GraphImpl@2883283a\nCharlie is 65\nDavid is 42\nEd is 55\nFran is 50\n"
      },
      "dateCreated": "Dec 4, 2016 5:27:52 PM",
      "dateStarted": "Dec 5, 2016 7:42:02 AM",
      "dateFinished": "Dec 5, 2016 7:42:05 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Snippet 3 - zadanie",
      "text": "%spark\n\n/*\n    Waszym zadaniem jest wyświetlenie opisu relacji \"kto lubi kogo\". Patrzcie -\u003e Oczekiwany rezultat\n*/\n\nimport org.apache.spark.graphx._\nimport org.apache.spark.rdd.RDD\n\n//for (triplet \u003c- graph.triplets.collect) {\n /**\n   * Triplet has the following Fields:\n   *   triplet.srcAttr: (String, Int) // triplet.srcAttr._1 is the name\n   *   triplet.dstAttr: (String, Int)\n   *   triplet.attr: Int\n   *   triplet.srcId: VertexId\n   *   triplet.dstId: VertexId\n   */\n//}\n\n/*\nOczekiwany rezultat:\n\n    Bob likes Alice\n    Bob likes David\n    Charlie likes Bob\n    Charlie likes Fran\n    David likes Alice\n    Ed likes Bob\n    Ed likes Charlie\n    Ed likes Fran\n*/\n",
      "dateUpdated": "Dec 5, 2016 7:44:15 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {},
          "map": {
            "baseMapType": "Streets",
            "isOnline": true,
            "pinCols": []
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1480873196661_-838860750",
      "id": "20161204-173956_763685756",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark.graphx._\n\nimport org.apache.spark.rdd.RDD\nBob likes Alice\nBob likes David\nCharlie likes Bob\nCharlie likes Fran\nDavid likes Alice\nEd likes Bob\nEd likes Charlie\nEd likes Fran\n"
      },
      "dateCreated": "Dec 4, 2016 5:39:56 PM",
      "dateStarted": "Dec 5, 2016 7:43:46 AM",
      "dateFinished": "Dec 5, 2016 7:43:47 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Snippet 4 - przyklad",
      "text": "%spark\n\nimport org.apache.spark.graphx._\nimport org.apache.spark.rdd.RDD\n\n// Define a class to more clearly model the user property\ncase class User(name: String, age: Int, inDeg: Int, outDeg: Int)\n// Create a user Graph\nval initialUserGraph: Graph[User, Int] \u003d graph.mapVertices{ case (id, (name, age)) \u003d\u003e User(name, age, 0, 0) }\n\n// Fill in the degree information\nval userGraph \u003d initialUserGraph.outerJoinVertices(initialUserGraph.inDegrees) {\n  case (id, u, inDegOpt) \u003d\u003e User(u.name, u.age, inDegOpt.getOrElse(0), u.outDeg)\n}.outerJoinVertices(initialUserGraph.outDegrees) {\n  case (id, u, outDegOpt) \u003d\u003e User(u.name, u.age, u.inDeg, outDegOpt.getOrElse(0))\n}\n\n",
      "dateUpdated": "Dec 5, 2016 7:47:57 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {},
          "map": {
            "baseMapType": "Streets",
            "isOnline": true,
            "pinCols": []
          }
        },
        "enabled": true,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1480874709794_179634469",
      "id": "20161204-180509_978359032",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark.graphx._\n\nimport org.apache.spark.rdd.RDD\n\ndefined class User\n\ninitialUserGraph: org.apache.spark.graphx.Graph[User,Int] \u003d org.apache.spark.graphx.impl.GraphImpl@154e8bee\n\nuserGraph: org.apache.spark.graphx.Graph[User,Int] \u003d org.apache.spark.graphx.impl.GraphImpl@30d46d5\n"
      },
      "dateCreated": "Dec 4, 2016 6:05:09 PM",
      "dateStarted": "Dec 5, 2016 7:47:57 AM",
      "dateFinished": "Dec 5, 2016 7:47:59 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Snippet 5 - zadanie",
      "text": "%spark\n\n/*\n    Waszym zadaniem jest wypisanie imienia użytkownika oraz liczby like’ów jaka dany użytkownik otrzymał\n*/\n\nimport org.apache.spark.graphx._\nimport org.apache.spark.rdd.RDD\n\n\n/*\nOczekiwany rezultat:\n\n    User 1 is called Alice and is liked by 2 people.\n    User 2 is called Bob and is liked by 2 people.\n    User 3 is called Charlie and is liked by 1 people.\n    User 4 is called David and is liked by 1 people.\n    User 5 is called Ed and is liked by 0 people.\n    User 6 is called Fran and is liked by 2 people.\n*/\n",
      "dateUpdated": "Dec 5, 2016 7:50:45 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {},
          "map": {
            "baseMapType": "Streets",
            "isOnline": true,
            "pinCols": []
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1480884087313_-1267234363",
      "id": "20161204-204127_1557898804",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark.graphx._\n\nimport org.apache.spark.rdd.RDD\nUser 1 is called Alice and is liked by 2 people.\nUser 2 is called Bob and is liked by 2 people.\nUser 3 is called Charlie and is liked by 1 people.\nUser 4 is called David and is liked by 1 people.\nUser 5 is called Ed and is liked by 0 people.\nUser 6 is called Fran and is liked by 2 people.\n"
      },
      "dateCreated": "Dec 4, 2016 8:41:27 PM",
      "dateStarted": "Dec 5, 2016 7:49:49 AM",
      "dateFinished": "Dec 5, 2016 7:49:50 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Snippet 6 - zadanie",
      "text": "%spark\n\n/*\n    Waszym zadaniem jest wypisanie imion osob ktore dali innym tyle samo like’ow ile otrzymali od innych\n*/\n\nimport org.apache.spark.graphx._\nimport org.apache.spark.rdd.RDD\n\n\n/*\nOczekiwany rezultat:\n\n    Bob\n    David\n*/\n\n",
      "dateUpdated": "Dec 5, 2016 7:51:58 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {},
          "map": {
            "baseMapType": "Streets",
            "isOnline": true,
            "pinCols": []
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "lineNumbers": false,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1480880423177_1549703924",
      "id": "20161204-194023_631072155",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark.graphx._\n\nimport org.apache.spark.rdd.RDD\nBob\nDavid\n"
      },
      "dateCreated": "Dec 4, 2016 7:40:23 PM",
      "dateStarted": "Dec 5, 2016 7:51:44 AM",
      "dateFinished": "Dec 5, 2016 7:51:45 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Snippet 7 - przyklad",
      "text": "%spark\n\nimport org.apache.spark.graphx._\nimport org.apache.spark.rdd.RDD\n\n// Find the oldest follower for each user\nval oldestFollower: VertexRDD[(String, Int)] \u003d userGraph.aggregateMessages[(String, Int)](\n  // For each edge send a message to the destination vertex with the attribute of the source vertex\n  edge \u003d\u003e edge.sendToDst(edge.srcAttr.name, edge.srcAttr.age),\n  // To combine messages take the message for the older follower\n  (a, b) \u003d\u003e if (a._2 \u003e b._2) a else b\n  )\n  \noldestFollower.collect.foreach {\n   case (id, str) \u003d\u003e println(str)\n}",
      "dateUpdated": "Dec 5, 2016 7:52:48 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {},
          "map": {
            "baseMapType": "Streets",
            "isOnline": true,
            "pinCols": []
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1480884866061_-254272063",
      "id": "20161204-205426_379737290",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark.graphx._\n\nimport org.apache.spark.rdd.RDD\n\noldestFollower: org.apache.spark.graphx.VertexRDD[(String, Int)] \u003d VertexRDDImpl[58] at RDD at VertexRDD.scala:57\n(David,42)\n(Charlie,65)\n(Ed,55)\n(Bob,27)\n(Charlie,65)\n"
      },
      "dateCreated": "Dec 4, 2016 8:54:26 PM",
      "dateStarted": "Dec 5, 2016 7:52:48 AM",
      "dateFinished": "Dec 5, 2016 7:52:50 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Snippet 8 - zadanie",
      "text": "%spark\n\n\n/*\n    Waszym zadaniem jest znalezienie dla kazdego usera imienia jego najstarszego followera\n*/\n\nimport org.apache.spark.graphx._\nimport org.apache.spark.rdd.RDD\n\n// Find the oldest follower for each user\nval oldestFollower: VertexRDD[(String, Int)] \u003d userGraph.aggregateMessages[(String, Int)](\n  // For each edge send a message to the destination vertex with the attribute of the source vertex\n  edge \u003d\u003e edge.sendToDst(edge.srcAttr.name, edge.srcAttr.age),\n  // To combine messages take the message for the older follower\n  (a, b) \u003d\u003e if (a._2 \u003e b._2) a else b\n  )\n\nuserGraph.vertices.leftJoin(oldestFollower) { (id, user, optOldestFollower) \u003d\u003e\n  /**\n   *\n   * Try using the match syntax:\n   *\n   *  optOldestFollower match {\n   *    case None \u003d\u003e \"No followers! implement me!\"\n   *    case Some((name, age)) \u003d\u003e \"implement me!\"\n   *  }\n   *\n   */\n}\n\n/*\n    David is the oldest follower of Alice.\n    Charlie is the oldest follower of Bob.\n    Ed is the oldest follower of Charlie.\n    Bob is the oldest follower of David.\n    Ed does not have any followers.\n    Charlie is the oldest follower of Fran.\n*/",
      "dateUpdated": "Dec 5, 2016 7:55:01 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {},
          "map": {
            "baseMapType": "Streets",
            "isOnline": true,
            "pinCols": []
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1480885009730_1434607042",
      "id": "20161204-205649_700958540",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark.graphx._\n\nimport org.apache.spark.rdd.RDD\n\noldestFollower: org.apache.spark.graphx.VertexRDD[(String, Int)] \u003d VertexRDDImpl[62] at RDD at VertexRDD.scala:57\nDavid is the oldest follower of Alice.\nCharlie is the oldest follower of Bob.\nEd is the oldest follower of Charlie.\nBob is the oldest follower of David.\nEd does not have any followers.\nCharlie is the oldest follower of Fran.\n"
      },
      "dateCreated": "Dec 4, 2016 8:56:49 PM",
      "dateStarted": "Dec 5, 2016 7:54:44 AM",
      "dateFinished": "Dec 5, 2016 7:54:46 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Snippet 9 - zadanie",
      "text": "%spark\n\n/*\n    Waszym zadaniem jest znalezienie sredniej wieku followerso\u0027w dla kazdego uzytkownika\n*/\n\nimport org.apache.spark.graphx._\nimport org.apache.spark.rdd.RDD\n\n\nval averageAge: VertexRDD[Double] \u003d userGraph.aggregateMessages[(Int, Double)](\n  // map function returns a tuple of (1, Age)\n  // put map function here,\n  // reduce function combines (sumOfFollowers, sumOfAge)\n  // put reduce function here\n  ).mapValues((id, p) \u003d\u003e p._2 / p._1)\n\n// Display the results\nuserGraph.vertices.leftJoin(averageAge) { (id, user, optAverageAge) \u003d\u003e\n  optAverageAge match {\n    case None \u003d\u003e s\"${user.name} does not have any followers.\"\n    case Some(avgAge) \u003d\u003e s\"The average age of ${user.name}\\\u0027s followers is $avgAge.\"\n  }\n}.collect.foreach { case (id, str) \u003d\u003e println(str) }\n\n/*\nOczekiwany rezultat:\n\nThe average age of Alice\u0027s followers is 34.5.\nThe average age of Bob\u0027s followers is 60.0.\nThe average age of Charlie\u0027s followers is 55.0.\nThe average age of David\u0027s followers is 27.0.\nEd does not have any followers.\nThe average age of Fran\u0027s followers is 60.0.\n\n*/\n",
      "dateUpdated": "Dec 5, 2016 7:56:23 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {},
          "map": {
            "baseMapType": "Streets",
            "isOnline": true,
            "pinCols": []
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1480880585077_2053137731",
      "id": "20161204-194305_1917569452",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark.graphx._\n\nimport org.apache.spark.rdd.RDD\n\naverageAge: org.apache.spark.graphx.VertexRDD[Double] \u003d VertexRDDImpl[70] at RDD at VertexRDD.scala:57\nThe average age of Alice\u0027s followers is 34.5.\nThe average age of Bob\u0027s followers is 60.0.\nThe average age of Charlie\u0027s followers is 55.0.\nThe average age of David\u0027s followers is 27.0.\nEd does not have any followers.\nThe average age of Fran\u0027s followers is 60.0.\n"
      },
      "dateCreated": "Dec 4, 2016 7:43:05 PM",
      "dateStarted": "Dec 5, 2016 7:56:07 AM",
      "dateFinished": "Dec 5, 2016 7:56:08 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Snippet 10 - zadanie ConnectedComponents",
      "text": "%spark\n\n/*\n    Waszym zadaniem jest jest wywolanie alogrytmu connectedComponents na grafie older graph\n    A nastepnie wypisaniu skladowych connected components\n*/\n\nimport org.apache.spark.graphx._\nimport org.apache.spark.rdd.RDD\n\nval olderGraph \u003d userGraph.subgraph(vpred \u003d (id, user) \u003d\u003e user.age \u003e\u003d 30)\n\n// compute the connected components graph here\n\n\n// display the component id of each user:\nolderGraph.vertices.leftJoin(cc.vertices) {\n  case (id, user, comp) \u003d\u003e s\"${user.name} is in component ${comp.get}\"\n}.collect.foreach{ case (id, str) \u003d\u003e println(str) }\n\n/*\nOczekiwany rezultat:\n\n    Charlie is in component 3\n    David is in component 4\n    Ed is in component 3\n    Fran is in component 3\n*/",
      "dateUpdated": "Dec 5, 2016 5:55:21 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {},
          "map": {
            "baseMapType": "Streets",
            "isOnline": true,
            "pinCols": []
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1480880869202_1832108496",
      "id": "20161204-194749_1466466089",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark.graphx._\n\nimport org.apache.spark.rdd.RDD\n\nolderGraph: org.apache.spark.graphx.Graph[User,Int] \u003d org.apache.spark.graphx.impl.GraphImpl@9bbf367\n\ncc: org.apache.spark.graphx.Graph[org.apache.spark.graphx.VertexId,Int] \u003d org.apache.spark.graphx.impl.GraphImpl@2ab5f8c3\nCharlie is in component 3\nDavid is in component 4\nEd is in component 3\nFran is in component 3\n"
      },
      "dateCreated": "Dec 4, 2016 7:47:49 PM",
      "dateStarted": "Dec 5, 2016 7:57:10 AM",
      "dateFinished": "Dec 5, 2016 7:57:12 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Snippet 11 - zadanie PageRank",
      "text": "%spark\n\n/*\n    Waszym zadaniem jest znalezienie dla każdego użytkownika wartości (ranking) według Page Rank\n*/\n\nimport org.apache.spark.graphx._\nimport org.apache.spark.rdd.RDD\n\n// Load the edges as a graph\nval graph \u003d GraphLoader.edgeListFile(sc, \"data/followers.txt\")\n// run dynamic PageRank on graph object with tolerance 0.0001\nval ranks \u003d // Iplement here\n// Join the ranks with the usernames\nval users \u003d sc.textFile(\"data/users.txt\").map { line \u003d\u003e\n  val fields \u003d line.split(\",\")\n  (fields(0).toLong, fields(1))\n}\nval ranksByUsername \u003d users.join(ranks).map {\n  case (id, (username, rank)) \u003d\u003e (username, rank)\n}\n// Print the result\nprintln(ranksByUsername.collect().mkString(\"\\n\"))\n\n/*\nOczekiwany rezultat:\n    (justinbieber,0.15)\n    (matei_zaharia,0.7013599933629602)\n    (ladygaga,1.390049198216498)\n    (BarackObama,1.4588814096664682)\n    (jeresig,0.9993442038507723)\n    (odersky,1.2973176314422592)\n*/",
      "dateUpdated": "Dec 5, 2016 6:52:58 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {},
          "map": {
            "baseMapType": "Streets",
            "isOnline": true,
            "pinCols": []
          }
        },
        "enabled": true,
        "title": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1480956372786_1494069483",
      "id": "20161205-164612_1410792175",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark.graphx._\n\nimport org.apache.spark.rdd.RDD\n\ngraph: org.apache.spark.graphx.Graph[Int,Int] \u003d org.apache.spark.graphx.impl.GraphImpl@24a653a\n\nranks: org.apache.spark.graphx.VertexRDD[Double] \u003d VertexRDDImpl[897] at RDD at VertexRDD.scala:57\n\nusers: org.apache.spark.rdd.RDD[(Long, String)] \u003d MapPartitionsRDD[902] at map at \u003cconsole\u003e:31\n\nranksByUsername: org.apache.spark.rdd.RDD[(String, Double)] \u003d MapPartitionsRDD[906] at map at \u003cconsole\u003e:37\n(justinbieber,0.15)\n(matei_zaharia,0.7013599933629602)\n(ladygaga,1.390049198216498)\n(BarackObama,1.4588814096664682)\n(jeresig,0.9993442038507723)\n(odersky,1.2973176314422592)\n"
      },
      "dateCreated": "Dec 5, 2016 4:46:12 PM",
      "dateStarted": "Dec 5, 2016 5:51:35 PM",
      "dateFinished": "Dec 5, 2016 5:51:55 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Snippet 12 - zadanie TriangleCount",
      "text": "%spark\n\n/*\n     Dla każdego użytkownika wylicz jego trójki (triangle counting)\n*/\n\nimport org.apache.spark.graphx._\nimport org.apache.spark.rdd.RDD\n\n// Load the edges in canonical order and partition the graph for triangle count\nval graph \u003d GraphLoader.edgeListFile(sc, \"data/followers.txt\", true)\n  .partitionBy(PartitionStrategy.RandomVertexCut)\n// Find the connected components and get vertices\n\n// Join the triangle counts with the usernames\nval users \u003d sc.textFile(\"data/users.txt\").map { line \u003d\u003e\n  val fields \u003d line.split(\",\")\n  (fields(0).toLong, fields(1))\n}\nval triCountByUsername \u003d users.join(triCounts).map { case (id, (username, tc)) \u003d\u003e\n  (username, tc)\n}\n// Print the result\nprintln(triCountByUsername.collect().mkString(\"\\n\"))\n\n/*\nOczekiwany rezultat:\n    (justinbieber,0)\n    (matei_zaharia,1)\n    (ladygaga,0)\n    (BarackObama,0)\n    (jeresig,1)\n    (odersky,1)\n*/",
      "dateUpdated": "Dec 5, 2016 6:53:27 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {},
          "map": {
            "baseMapType": "Streets",
            "isOnline": true,
            "pinCols": []
          }
        },
        "enabled": true,
        "title": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1480956409562_-2121953921",
      "id": "20161205-164649_1200575871",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark.graphx._\n\nimport org.apache.spark.rdd.RDD\n\ngraph: org.apache.spark.graphx.Graph[Int,Int] \u003d org.apache.spark.graphx.impl.GraphImpl@306cf5f\n\ntriCounts: org.apache.spark.graphx.VertexRDD[Int] \u003d VertexRDDImpl[976] at RDD at VertexRDD.scala:57\n\nusers: org.apache.spark.rdd.RDD[(Long, String)] \u003d MapPartitionsRDD[981] at map at \u003cconsole\u003e:35\n\ntriCountByUsername: org.apache.spark.rdd.RDD[(String, Int)] \u003d MapPartitionsRDD[985] at map at \u003cconsole\u003e:41\n(justinbieber,0)\n(matei_zaharia,1)\n(ladygaga,0)\n(BarackObama,0)\n(jeresig,1)\n(odersky,1)\n"
      },
      "dateCreated": "Dec 5, 2016 4:46:49 PM",
      "dateStarted": "Dec 5, 2016 5:52:01 PM",
      "dateFinished": "Dec 5, 2016 5:52:03 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Zadanie 2",
      "text": "",
      "dateUpdated": "Dec 4, 2016 9:08:18 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {},
          "map": {
            "baseMapType": "Streets",
            "isOnline": true,
            "pinCols": []
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1480783011851_1837289024",
      "id": "20161203-163651_570312931",
      "dateCreated": "Dec 3, 2016 4:36:51 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Apache Spark - GraphX",
  "id": "2C4QDEKRU",
  "angularObjects": {
    "2C2P64GKQ:shared_process": [],
    "2C3KHZ36P:shared_process": [],
    "2C34ZSKQ3:shared_process": [],
    "2C3QY283C:shared_process": [],
    "2C5NF8QXR:shared_process": [],
    "2C64E8ZWU:shared_process": [],
    "2C3ED74D7:shared_process": [],
    "2C4G94W63:shared_process": [],
    "2C4A7E33R:shared_process": []
  },
  "config": {},
  "info": {}
}